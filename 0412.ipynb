{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15826f11",
   "metadata": {},
   "source": [
    "## Selecting number of clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!{sys.executable} -m pip install kneed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c02e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn imports\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import silhouette_samples\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pandas and numpy imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "\n",
    "# import knee detection algorithm\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# set sns theme and set pandas to display all rows and columns\n",
    "sns.set_theme()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36989c48",
   "metadata": {},
   "source": [
    "### Load Iris dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a137467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "iris_df = pd.DataFrame(\n",
    "    iris['data'],\n",
    "    columns=iris['feature_names']\n",
    ")\n",
    "\n",
    "\n",
    "# Add label to the dataset\n",
    "iris_df['label'] = iris['target_names'][iris['target']]\n",
    "\n",
    "# Remove versicolor class\n",
    "iris_df = iris_df[iris_df['label'] != 'versicolor']\n",
    "\n",
    "# Keep only petal length and petal width\n",
    "iris_df = iris_df.filter(\n",
    "    items=[\n",
    "        'petal length (cm)', \n",
    "        'petal width (cm)', \n",
    "        'label'\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af723ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(\n",
    "    iris_df, \n",
    "    x='petal length (cm)', \n",
    "    y='petal width (cm)', \n",
    "    hue='label'\n",
    ")\n",
    "\n",
    "plt.title('Raw data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ef7780a",
   "metadata": {},
   "source": [
    "## Selecting optimal number of clusters - inertia knee plot\n",
    "\n",
    "In this section we sill Elbow (Knee) Method for Inertia to analyze clustering quality.\n",
    "\n",
    "Elbow (Knee) Method for Inertia is a technique used to determine the optimal number of clusters (k) in K-means clustering by plotting the inertia (sum of squared distances of data points to their closest cluster center) against different k values, and selecting the k where the rate of decrease in inertia sharply changes, resembling an \"elbow\" in the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac52a968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up multiple values of k \n",
    "num_clusters = [1,2,3,4,5,6,7]\n",
    "\n",
    "# List used to store inertia\n",
    "inertia_list = []\n",
    "# List used to store clusters\n",
    "clustering_result_list = []\n",
    "\n",
    "# Set up standard scaler\n",
    "cluster_data = iris_df[['petal length (cm)', 'petal width (cm)']]\n",
    "\n",
    "# Standardize the data\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(cluster_data)\n",
    "cluster_data = standard_scaler.transform(cluster_data)\n",
    "cluster_data = pd.DataFrame(\n",
    "    cluster_data, \n",
    "    columns = ['petal length (cm)', 'petal width (cm)']\n",
    ")\n",
    "\n",
    "# Perform clustering for multiple resolutons\n",
    "for num_clust in num_clusters:\n",
    "    \n",
    "    # Perform clustering for current number of clusters\n",
    "    kmeans = KMeans(n_clusters=num_clust, n_init='auto')\n",
    "    kmeans.fit(cluster_data)\n",
    "    \n",
    "    # Calculate inertia\n",
    "    inertia_list.append(kmeans.inertia_)\n",
    "    \n",
    "    # Add clustering result to the list\n",
    "    current_clustering = cluster_data.copy()\n",
    "    current_clustering['clusters'] = kmeans.labels_\n",
    "    current_clustering['cluster_num'] = num_clust\n",
    "    clustering_result_list.append(current_clustering)\n",
    "    \n",
    "# Merge results for all values of num_clust\n",
    "merged_clustering_result = pd.concat(\n",
    "    clustering_result_list, \n",
    "    axis=0, \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Plot all clusterings\n",
    "g = sns.FacetGrid(\n",
    "    merged_clustering_result, \n",
    "    col=\"cluster_num\", \n",
    "    col_wrap=3, \n",
    "    hue=\"clusters\"\n",
    ")\n",
    "g.map(\n",
    "    sns.scatterplot, \n",
    "    'petal length (cm)', \n",
    "    'petal width (cm)', \n",
    "    alpha=.7\n",
    ")\n",
    "g.add_legend()    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6248975e",
   "metadata": {},
   "source": [
    "In this situation inertia-knee method does bad job of separating the clusters. We use **kneedle** library for automatic knee detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c40b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kneedle = KneeLocator(\n",
    "    num_clusters, \n",
    "    inertia_list, \n",
    "    curve=\"convex\", \n",
    "    direction=\"decreasing\"\n",
    ")\n",
    "kneedle.plot_knee()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f6bcdfc4",
   "metadata": {},
   "source": [
    "## Selecting optimal number of clusters - siluethe score\n",
    "\n",
    "In this section we sill use Silhouette Score to analyze clustering quality.\n",
    "\n",
    "Silhouette Score is a metric that measures the quality of a clustering solution by calculating the average silhouette coefficient for each data point, which considers both cohesion (how close points are within a cluster) and separation (how distinct clusters are from each other), with values ranging from -1 (poor clustering) to 1 (well-defined clusters).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e68701a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up multiple values of k\n",
    "num_clusters = [2,3,4,5,6,7]\n",
    "\n",
    "# Lists for storing results\n",
    "silouethe_score_list = []\n",
    "\n",
    "# Set up standard scaler\n",
    "cluster_data = iris_df[['petal length (cm)', 'petal width (cm)']]\n",
    "\n",
    "standard_scaler = StandardScaler()\n",
    "standard_scaler.fit(cluster_data)\n",
    "cluster_data = standard_scaler.transform(cluster_data)\n",
    "cluster_data = pd.DataFrame(\n",
    "    cluster_data, \n",
    "    columns = ['petal length (cm)', 'petal width (cm)']\n",
    ")\n",
    "\n",
    "# Perform clustering for multiple resolutons\n",
    "\n",
    "# Lower y coordinate for the first silhouette plot\n",
    "y_lower = 10\n",
    "\n",
    "for num_clust in num_clusters:\n",
    "    \n",
    "    # Perform clustering for current number of clusters\n",
    "    kmeans = KMeans(n_clusters=num_clust, n_init='auto')\n",
    "    kmeans.fit(cluster_data)\n",
    "        \n",
    "    # Calculate average silhouette score\n",
    "    silhouette_scr = silhouette_score(cluster_data, kmeans.labels_)\n",
    "    silouethe_score_list.append(silhouette_scr)\n",
    "    # Calculate silhouette score for each data point\n",
    "    sample_silhouette_values = silhouette_samples(cluster_data, kmeans.labels_)\n",
    "    \n",
    "    # Plot clustering and silouethes\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,5))\n",
    "    \n",
    "    # Plot siluethe scores for points belonging to each cluster\n",
    "    for clust_i in range(num_clust):\n",
    "        \n",
    "        # Get points bellogning to the current cluster\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[\n",
    "            kmeans.labels_ == clust_i\n",
    "        ]\n",
    "        \n",
    "        # Sort points by silhouette value\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "        \n",
    "        # Get size of current cluster\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        \n",
    "        # Get upper value of y cooridnate for current cluster\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "        \n",
    "        # Fill values between y_lower and y_upper with silhouette score values\n",
    "        # for data points\n",
    "        color = cm.nipy_spectral(float(clust_i) / num_clust)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7\n",
    "        )\n",
    "        \n",
    "        # Label the silhouette plots with their cluster numbers \n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(clust_i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10\n",
    "    \n",
    "    # Set title and labels silhouette subplot\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_scr, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    # Clear the yaxis labels / ticks\n",
    "    ax1.set_yticks([]) \n",
    "    # Set x-ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "    \n",
    "    # Map cluster labels to cluster colors, nipy_spectral provides\n",
    "    # colors evenly distributed across the entire range of values.\n",
    "    colors = cm.nipy_spectral(kmeans.labels_.astype(float) / num_clust)\n",
    "    \n",
    "    # 2nd Plot showing the actual clustering scatteplot\n",
    "    ax2.scatter(\n",
    "        cluster_data.values[:, 0], \n",
    "        cluster_data.values[:, 1],\n",
    "        marker=\".\", s=30, lw=0, \n",
    "        alpha=0.7, c=colors, \n",
    "        edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    # Get cluster centers\n",
    "    centers = kmeans.cluster_centers_\n",
    "    \n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(\n",
    "        centers[:, 0],\n",
    "        centers[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=\"white\",\n",
    "        alpha=1,\n",
    "        s=200,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, s=50, edgecolor=\"k\")\n",
    "\n",
    "    # Set title and labels for scatterplot\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "    \n",
    "    # Add main title\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering\",\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall siluethe scores\n",
    "plt.plot(num_clusters, silouethe_score_list)\n",
    "plt.title('Silhouette score')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette score value')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa993e17",
   "metadata": {},
   "source": [
    "## Artificial dataset - 5 clusters - case 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6179c1bd",
   "metadata": {},
   "source": [
    "In this section we will perform clustering on artificial dataset created with **make_blobs** function.\n",
    "\n",
    "**make_blobs** is a function provided by the scikit-learn (sklearn) library in Python, which is used to generate synthetic datasets for clustering or classification tasks. It creates a set of Gaussian blobs with controllable properties such as the number of blobs, their centroids, standard deviations, and the total number of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748c2936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y_true = make_blobs(\n",
    "    n_samples=500, centers=5, cluster_std=0.60, random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b325efff",
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_df = pd.DataFrame(data=X, columns=['Feature 1', 'Feature 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a566d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(artificial_df, x='Feature 1', y='Feature 2', hue=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572a53d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different numbers of k to try out\n",
    "num_clusters = [2,3,4,5,6,7,8,9]\n",
    "# Storage for inertia value\n",
    "inertia_list = []\n",
    "# Storage for silhouette scores\n",
    "silhouette_score_list = []\n",
    "# List used to store clustering results\n",
    "clustering_result_list = []\n",
    "\n",
    "# Use StandardScaler to standardize data\n",
    "standard_scaler = StandardScaler()\n",
    "artificial_df = standard_scaler.fit_transform(artificial_df)\n",
    "artificial_df = pd.DataFrame(\n",
    "    data=artificial_df, \n",
    "    columns=['Feature 1', 'Feature 2']\n",
    ")\n",
    "\n",
    "# Perform clustering for different number of clusters\n",
    "for num_clust in num_clusters:\n",
    "    \n",
    "    # Perform k means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clust, n_init='auto')\n",
    "    kmeans.fit(artificial_df)\n",
    "    \n",
    "    # Calculate and store inertia & silhouette score\n",
    "    inertia_list.append(kmeans.inertia_)\n",
    "    silhouette_scr = silhouette_score(artificial_df, kmeans.labels_)\n",
    "    silhouette_score_list.append(silhouette_scr)\n",
    "    \n",
    "    # Add clustering result to list\n",
    "    current_clustering = artificial_df.copy()\n",
    "    current_clustering['clusters'] = kmeans.labels_\n",
    "    current_clustering['cluster_num'] = num_clust\n",
    "    clustering_result_list.append(current_clustering)\n",
    "    \n",
    "# Merge results for all values of num_clust\n",
    "merged_clustering_result = pd.concat(\n",
    "    clustering_result_list, \n",
    "    axis=0, \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Plot all clusterings\n",
    "g = sns.FacetGrid(\n",
    "    merged_clustering_result, \n",
    "    col=\"cluster_num\", \n",
    "    col_wrap=3, \n",
    "    hue=\"clusters\"\n",
    ")\n",
    "g.map(\n",
    "    sns.scatterplot, \n",
    "    'Feature 1', \n",
    "    'Feature 2', \n",
    "    alpha=.7\n",
    ")\n",
    "g.add_legend()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b1889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inertia\n",
    "kneedle = KneeLocator(\n",
    "    num_clusters, \n",
    "    inertia_list, \n",
    "    curve=\"convex\", \n",
    "    direction=\"decreasing\"\n",
    ")\n",
    "kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c4e039",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_clusters, silhouette_score_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b65f6f21",
   "metadata": {},
   "source": [
    "## Artificial dataset - 5 clusters - case 2\n",
    "\n",
    "In this section we will perform clustering on another artificial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4487cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "X, y_true = make_blobs(\n",
    "    n_samples=500, centers=5, cluster_std=0.6, random_state=0\n",
    ")\n",
    "\n",
    "artificial_df = pd.DataFrame(data=X, columns=['Feature 1', 'Feature 2'])\n",
    "\n",
    "sns.scatterplot(artificial_df, x='Feature 1', y='Feature 2', hue=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bf5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Various number of clusters\n",
    "num_clusters = [2,3,4,5,6,7,8,9]\n",
    "# List to store inertia values\n",
    "inertia_list = []\n",
    "# List to store silhouette scores\n",
    "silhouette_score_list = []\n",
    "\n",
    "# List used to store clusterings\n",
    "clustering_result_list = []\n",
    "\n",
    "# Use StandardScaler to standardize data\n",
    "standard_scaler = StandardScaler()\n",
    "artificial_df = standard_scaler.fit_transform(artificial_df)\n",
    "artificial_df = pd.DataFrame(\n",
    "    data=artificial_df, \n",
    "    columns=['Feature 1', 'Feature 2']\n",
    ")\n",
    "\n",
    "# Perform clustering for different number of clusters\n",
    "for num_clust in num_clusters:\n",
    "    \n",
    "    # Perform k means clustering\n",
    "    kmeans = KMeans(n_clusters=num_clust, n_init='auto')\n",
    "    kmeans.fit(artificial_df)\n",
    "    \n",
    "    # Calculate and store inertia & silhouette score\n",
    "    inertia_list.append(kmeans.inertia_)\n",
    "    silhouette_scr = silhouette_score(artificial_df, kmeans.labels_)\n",
    "    silhouette_score_list.append(silhouette_scr)\n",
    "    \n",
    "    # Add clustering result to the list\n",
    "    current_clustering = artificial_df.copy()\n",
    "    current_clustering['clusters'] = kmeans.labels_\n",
    "    current_clustering['cluster_num'] = num_clust\n",
    "    clustering_result_list.append(current_clustering)\n",
    "    \n",
    "# Merge results for all values of num_clust\n",
    "merged_clustering_result = pd.concat(\n",
    "    clustering_result_list, \n",
    "    axis=0, \n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Plot all clusterings\n",
    "g = sns.FacetGrid(\n",
    "    merged_clustering_result, \n",
    "    col=\"cluster_num\", \n",
    "    col_wrap=3, \n",
    "    hue=\"clusters\"\n",
    ")\n",
    "g.map(\n",
    "    sns.scatterplot, \n",
    "    'Feature 1', \n",
    "    'Feature 2', \n",
    "    alpha=.7\n",
    ")\n",
    "g.add_legend()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c42bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot inertia plot and curve\n",
    "kneedle = KneeLocator(\n",
    "    num_clusters, \n",
    "    inertia_list, \n",
    "    S=2, \n",
    "    curve=\"convex\", \n",
    "    direction=\"decreasing\"\n",
    ")\n",
    "kneedle.plot_knee()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26954c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(num_clusters, silhouette_score_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
