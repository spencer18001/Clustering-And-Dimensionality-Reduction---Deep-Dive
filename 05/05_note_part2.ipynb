{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spencer18001/Clustering-And-Dimensionality-Reduction---Deep-Dive/blob/main/05/05_note_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PCA Part2"
      ],
      "metadata": {
        "id": "yhj8mdMPWDTt"
      },
      "id": "yhj8mdMPWDTt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "79. Principal component analysis for dimensionality reduction\n",
        "80. Demo: Performing PCA by using eigendecomposition - [code](https://github.com/spencer18001/Clustering-And-Dimensionality-Reduction---Deep-Dive/blob/main/05/0512.ipynb)\n",
        "81. Principal component analysis in sklearn\n",
        "82. Demo: PCA in sklearn (artificial data) - [code](https://github.com/spencer18001/Clustering-And-Dimensionality-Reduction---Deep-Dive/blob/main/05/0514.ipynb)\n",
        "83. Demo: PCA in sklearn (real data) - [code](https://github.com/spencer18001/Clustering-And-Dimensionality-Reduction---Deep-Dive/blob/main/05/0515.ipynb)\n",
        "    - loading plot\n",
        "84. Guidelines for choosing number of principal component\n",
        "85. Demo : Choosing number of principal components - [code](https://github.com/spencer18001/Clustering-And-Dimensionality-Reduction---Deep-Dive/blob/main/05/0517.ipynb)\n",
        "    - knee method\n",
        "    - de-noise\n",
        "    - 可視化的侷限\n",
        "86. Chapter summary"
      ],
      "metadata": {
        "id": "Jz7OGqSUba6s"
      },
      "id": "Jz7OGqSUba6s"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dimensionality Reduction"
      ],
      "metadata": {
        "id": "w2LpaD1wbozs"
      },
      "id": "w2LpaD1wbozs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "$Y=P^TX$\n",
        "- $P$: $p \\times p$\n",
        "- $P^T$: $p \\times p$\n",
        "- $X$: $p \\times n$\n",
        "- $Y$: $p \\times n$\n",
        "\n",
        "$Y^{'}=(P^{'})^TX$\n",
        "- $P^{'}=P_{:,p_1}$: $p \\times p_1$ $\\hspace{1em}$ $(p_1 < p)$\n",
        "- $(P^{'})^T$: $p_1 \\times p$\n",
        "- $X$: $p \\times n$\n",
        "- $Y^{'}$: $p_1 \\times n$"
      ],
      "metadata": {
        "id": "6hWjoAIuic6L"
      },
      "id": "6hWjoAIuic6L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA 用途:\n",
        "- 降低維度, 保持大部份的 variance\n",
        "- 對資料進行去噪 (de-noising)\n",
        "    - 多數 variance 為資訊\n",
        "    - 少數 variance 為雜訊\n",
        "- 資料視覺化"
      ],
      "metadata": {
        "id": "uhE4SRGRb9Rw"
      },
      "id": "uhE4SRGRb9Rw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PCA 限制"
      ],
      "metadata": {
        "id": "oRa0AD03dY5n"
      },
      "id": "oRa0AD03dY5n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 要求所有 feature 具有相似的 scale\n",
        "- 對 outlier 很敏感\n",
        "    - outlier 會大大影響 variance\n",
        "- principal component 不好解讀\n",
        "- 無法捕捉非線性關係"
      ],
      "metadata": {
        "id": "Y0u8vUOjd-Wm"
      },
      "id": "Y0u8vUOjd-Wm"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loading Plot"
      ],
      "metadata": {
        "id": "T2bWh00JecJ7"
      },
      "id": "T2bWh00JecJ7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 可視化原始 feature 對 principal components 的貢獻程度\n",
        "- loading: 原始 feature 對 principal components 的貢獻程度的向量"
      ],
      "metadata": {
        "id": "ruC9XDsaevXr"
      },
      "id": "ruC9XDsaevXr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\begin{aligned}\n",
        "Y_{:,j} &= P^TX_{:,j} \\\\\n",
        "        &= \\sum_{k=1}^{p}(P^T)_{:,k}(X_{:,j})_{k}\n",
        "\\end{aligned}$\n",
        "\n",
        "loading: $(P^T)_{:,k}$"
      ],
      "metadata": {
        "id": "KlDf8JGQoft1"
      },
      "id": "KlDf8JGQoft1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### scikit-learn PCA"
      ],
      "metadata": {
        "id": "HwPu4fh4r0gv"
      },
      "id": "HwPu4fh4r0gv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "class sklearn.decomposition.PCA(n_components=None, *, copy=True, whiten=False,\n",
        "  svd_solver='auto', tol=0.0, iterated_power='auto', n_oversamples=10,\n",
        "  power_iteration_normalizer='auto', random_state=None)\n",
        "```"
      ],
      "metadata": {
        "id": "1gW38GAAsSyG"
      },
      "id": "1gW38GAAsSyG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "svd_solver: 求解 eigenvector、eigenvalue\n",
        "- `full`: SVD 求得精確 eigenvector、eigenvalue\n",
        "- `arpack`: 近似解\n",
        "  ```python\n",
        "  n_components <= min(n_features, n_samples)-1\n",
        "  ```\n",
        "- `randomized`: 近似解\n",
        "- 精確度: `full` > `arpack` > `randomized`\n",
        "- 效率: `full` < `arpack` < `randomized`\n",
        "- `default`: 依輸入資料的大小與 `n_components` 決定使用 `randomized` 或 `full`"
      ],
      "metadata": {
        "id": "hHtl3PN6ua_T"
      },
      "id": "hHtl3PN6ua_T"
    },
    {
      "cell_type": "markdown",
      "source": [
        "method:\n",
        "- `fit(X)`: 計算 principal component\n",
        "- `transform(X)`: 轉換座標軸\n",
        "- `fit_transform(X)`\n",
        "- `inverse_transform(X)`: 轉為原始座標軸\n",
        "    - `X`: 列向量對應一筆資料\n"
      ],
      "metadata": {
        "id": "c6QjW-pTuwmh"
      },
      "id": "c6QjW-pTuwmh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "attribute:\n",
        "- `components_`: principal component 為列向量的 transformation matrix\n",
        "- `explained_variance_`: eigenvalues\n",
        "- `explained_variance_ratio_`: normalized explained_variance_\n",
        "- `mean_`: 估計的 feature mean\n"
      ],
      "metadata": {
        "id": "ts15qW7ZviN1"
      },
      "id": "ts15qW7ZviN1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Principal Component 個數挑選"
      ],
      "metadata": {
        "id": "_htVhY-1r8MG"
      },
      "id": "_htVhY-1r8MG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 決定要保留 variance 的百分比\n",
        "- knee method\n",
        "    - 計算 explained variance percentage 的 cumulative sum\n",
        "    - 找到 elbow 點 (斜率變化最大的點)\n",
        "- 領域知識"
      ],
      "metadata": {
        "id": "WxHXXlMSw3ur"
      },
      "id": "WxHXXlMSw3ur"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}