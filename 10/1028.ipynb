{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!{sys.executable} -m pip install branca jinja2 requests folium\n",
    "\n",
    "import random\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "\n",
    "import hdbscan\n",
    "\n",
    "import folium"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data\n",
    "\n",
    "Flickr is an online photo management and sharing application developed by SmugMug. \n",
    "- Photo metadata like tags, descriptions and geospatial data is also available.\n",
    "\n",
    "The dataset contains 20K sets of photos records gathered from Flickr . This dataset is limited to a geographical bounding box which includes locations in the city of London, and photos are taken between 2014 and 2019.\n",
    "\n",
    "Citation: https://www.kaggle.com/datasets/amiralisa/flickr_london?select=london_20k.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr_df = pd.read_csv('data/geospatial/london_20k.csv')\n",
    "flickr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot map based on mean longitude/lattitude of the dataset\n",
    "m = folium.Map(location=[flickr_df['lat'].mean(), flickr_df['lon'].mean()], zoom_start=12)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display all the locations(points) where photos were taken\n",
    "for idx, row in flickr_df.iterrows():\n",
    "        folium.CircleMarker([row['lat'], row['lon']], radius=0.1, color=\"red\").add_to(m) \n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Points can also be shown as a scatterplot\n",
    "plt.figure(figsize=(10,10))\n",
    "sns.scatterplot(flickr_df, x='lat', y='lon',s=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spatial_clusters(clusterer, data_df, lat_key='lat', lon_key='lon'):\n",
    "    \n",
    "    # Get number of clusters and determine if there is noise\n",
    "    num_clust = len(set(clusterer.labels_))\n",
    "    add_const = 1 if -1 in clusterer.labels_ else 0\n",
    "\n",
    "    # Get colormap\n",
    "    cmap = matplotlib.colormaps['nipy_spectral']  \n",
    "    colors = list(cmap(np.linspace(0, 1, num_clust-add_const)))\n",
    "\n",
    "    # Shuffle collors to avoid similar colors being close to each other\n",
    "    # on the map\n",
    "    random.shuffle(colors)\n",
    "\n",
    "    # Use black for noise dots\n",
    "    if add_const == 1:\n",
    "        colors.insert(0, (0,0,0,1))\n",
    "    \n",
    "    # Get color for each dot\n",
    "    collor_list = [matplotlib.colors.to_hex(colors[clust+add_const]) for clust in clusterer.labels_]\n",
    "\n",
    "    # Plot map based on mean longitude/lattitude of the dataset\n",
    "    m_clust = folium.Map(location=[flickr_df['lat'].mean(), flickr_df['lon'].mean()], zoom_start=12)\n",
    "    # Add collored dots to the map\n",
    "    for idx in range(data_df.shape[0]):\n",
    "            folium.CircleMarker(\n",
    "                [data_df.loc[idx, lat_key], data_df.loc[idx, lon_key]], \n",
    "                radius=0.1, \n",
    "                color=collor_list[idx]\n",
    "            ).add_to(m_clust) \n",
    "\n",
    "    # Return map with dots for plotting\n",
    "    return(m_clust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform latitude and longitude to radians\n",
    "flickr_df['lat_rad'] = flickr_df['lat'].map(math.radians)\n",
    "flickr_df['lon_rad'] = flickr_df['lon'].map(math.radians)\n",
    "clust_data = flickr_df[['lat_rad', 'lon_rad']].to_numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBSCAN for geospatial clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_1m = 1/6371000\n",
    "eps = eps_1m*100\n",
    "clusterer = DBSCAN(eps=eps, min_samples=40, metric='haversine').fit(clust_data)\n",
    "unique_labels = np.unique(clusterer.labels_, return_counts=True)\n",
    "print(hdbscan.validity_index(clust_data, clusterer.labels_))\n",
    "print(pd.Series(unique_labels[1], index=unique_labels[0]).sort_values(ascending=False).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spatial_clusters(\n",
    "    clusterer=clusterer, \n",
    "    data_df=flickr_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_1m = 1/6371000\n",
    "eps = eps_1m*200\n",
    "clusterer = DBSCAN(eps=eps, min_samples=40, metric='haversine').fit(clust_data)\n",
    "unique_labels = np.unique(clusterer.labels_, return_counts=True)\n",
    "print(hdbscan.validity_index(clust_data, clusterer.labels_))\n",
    "print(pd.Series(unique_labels[1], index=unique_labels[0]).sort_values(ascending=False).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spatial_clusters(\n",
    "    clusterer=clusterer, \n",
    "    data_df=flickr_df\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDBSCAN clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HDDBSCAN - EOM \n",
    "clusterer = hdbscan.HDBSCAN(\n",
    "    min_samples=10, \n",
    "    min_cluster_size=40,\n",
    "    metric='haversine'\n",
    ").fit(clust_data)\n",
    "print(hdbscan.validity_index(clust_data, clusterer.labels_))\n",
    "unique_labels = np.unique(clusterer.labels_, return_counts=True)\n",
    "print(pd.Series(unique_labels[1], index=unique_labels[0]).sort_values(ascending=False).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spatial_clusters(\n",
    "    clusterer=clusterer, \n",
    "    data_df=flickr_df\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove noise points\n",
    "flickr_df['cluster'] = clusterer.labels_\n",
    "flickr_df_denoised = flickr_df[flickr_df['cluster'] != -1].filter(\n",
    "    ['owner', 'taken', 'tags', 'lat', 'lon', 'lat_rad', 'lon_rad', 'cluster']\n",
    ")\n",
    "\n",
    "flickr_df_denoised.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets pretend each phot comes from separate owner !!\n",
    "flickr_df['owner'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extend dataframe to have single tag per row\n",
    "\n",
    "# Drop all nan values\n",
    "flickr_df_denoised = flickr_df_denoised.dropna(subset=['tags'])\n",
    "\n",
    "# Split tag array into list\n",
    "flickr_df_denoised['tag_list'] = flickr_df_denoised['tags'].str.split(',')\n",
    "\n",
    "flickr_df_denoised = flickr_df_denoised.explode('tag_list')\n",
    "\n",
    "\n",
    "flickr_df_denoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exolode the list column\n",
    "flickr_df_denoised = flickr_df_denoised.drop(\n",
    "    columns=['tags']\n",
    ").rename(columns={'tag_list': 'tag'}).reset_index(drop=True)\n",
    "\n",
    "# Remove whitespaces from tags\n",
    "flickr_df_denoised['tag'] = flickr_df_denoised['tag'].str.strip()\n",
    "\n",
    "# Get tag frequencies\n",
    "tag_freq = flickr_df_denoised['tag'].value_counts(ascending=False)\n",
    "tag_freq.head(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find all places with graffiti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = flickr_df_denoised[flickr_df_denoised['tag']=='graffiti']\n",
    "clust_tag_count = tag_df.groupby('cluster')['cluster'].count().sort_values(ascending=False)\n",
    "tag_clusts = list(clust_tag_count[clust_tag_count > 40].index)\n",
    "clust_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cluster = flickr_df[flickr_df['cluster'].isin(tag_clusts)]\n",
    "m = folium.Map(location=[target_cluster['lat'].mean(), target_cluster['lon'].mean()], zoom_start=12)\n",
    "for idx, row in target_cluster.iterrows():\n",
    "        folium.CircleMarker([row['lat'], row['lon']], radius=0.1, color=\"red\").add_to(m) \n",
    "print(target_cluster.shape[0])\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_df = flickr_df_denoised[flickr_df_denoised['tag']=='museum']\n",
    "clust_tag_count = tag_df.groupby('cluster')['cluster'].count().sort_values(ascending=False)\n",
    "tag_clusts = list(clust_tag_count[clust_tag_count > 40].index)\n",
    "clust_tag_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cluster = flickr_df[flickr_df['cluster'].isin(tag_clusts)]\n",
    "m = folium.Map(location=[target_cluster['lat'].mean(), target_cluster['lon'].mean()], zoom_start=12)\n",
    "for idx, row in target_cluster.iterrows():\n",
    "        folium.CircleMarker([row['lat'], row['lon']], radius=0.1, color=\"red\").add_to(m) \n",
    "print(target_cluster.shape[0])\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test_env_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
